# Kafka의 동작 방식과 원리
> coding-start.tistory.com/132?category=790331

## 1. Kafka, 메시징 서버
kafka는 메시징 서버로 동작합니다. 여기에서 메시징 시스템이란 메시지라고 불리는 데이터 단위를 보내는 (publisher, producer) 에서 카프카에 `토픽` 이라는 각각의 메시지 저장소에 데이터를 저장하면, 가져가는 측(subscriber, consumer)이 원하는 토픽에서 데이터를 가져가게 되어있다. 

즉 메시지 시스템은 중앙에 메시징 시스템 서버를 두고 이렇게 메시지를 보내고(publish) 받는(subscribe) 형태의 통신 형태인 pub/sub 모델의 통신주고 입니다.

## 2. Pub/Sub 모델
- `Pub/Sub 모델` 은 비동기 메시징 전송 방식
- 발신자의 메시지에는 수신자가 정해져 있지 않은 상태로 발행한다.
- 구독을 신청한 수신자만이 정해진 메시지를 받을 수 있다.
- 수신자는 발신자 정보가 없어도 원하는 메시지만을 수신 가능하다.
### 2-1. 일반적인 통신(직접 연결)
- `A--------------> B`
	- 장점
		- 빠른 전송 속도와 전송 결과를 신속하게 알 수 있다
	- 단점
		- 장애가 발생할 경우 적절한 처리를 수신자 측에서 해주어야 함
		- 통신에 참여한 개체수가 많아 질 수록 일일이 다 연결하고 데이터를 전송해야 하기 때문에 확장성이 떨어진다.
### 2-2. `펍/섭 구조`
- `A ---------> <메시지 서버> -----큐-----> B`
	- 프로듀서가 메시지 서버에 메시지 데이터와 수신처 ID를 포함시켜 전달
	- 메시지 서버는 수신처 ID에 맞게 컨슈머들의 큐에 전달
	- 컨슈머들은 큐를 모니터링하고 있다가, 큐에 메시지가 전달되면 값을 가져감.
	- 장점
		- 메시징 시스템만 살아 있다면 프로듀서에서혹시나 통신개체가 하나 빠지거나 수신 불가능 상태가 되었어도 프로듀서에서 전달된 메시지는 유실되지 않는다.
		- 장애에서 복구한 통신 개체가 살아나면 메시지를 다시 안전하게 전달가능하다.
		- 메시징 시스템을 중심으로 연결되기 때문에 확장성이 용이
		- **리액티브 프로그래밍(비동기 처리로, MSA, RESTful API)에 아주 적합한 queue 역활 **
	- 단점
		- 직접 통신하지 않기 때문에, 메시지가 정확하게 전달되었는지 확인하는 등의 코드가 필요(복잡성 증가)
		- 메시징 서버를 한번 거쳐서 가기에 통신속도 오버헤드
		
## 3. 기존 메시징 시스템(Pub/Sub)과 Kafka의 차이
> 요약하자면 기존에 메시지 시스템에 집중되어있던 기능들을 펍/섭에 `위임`해줌으로써 메시지 시스템의 부하를 줄여주고, 여유로워진 리소스를 가지고 메시징 전달 성능에 집중시켰다.

기존 메시징 시스템을 사용하는 펍/섭 모델은 대규모 데이터를 메시징 시스템(건당 수MB) 을 통해 전달하기 보다는 간단한 이벤트(건당 수KB)를 서로 전송하는데 주로 사용되었다. 왜냐하면 메시징 시스템 내부의 교환기의 부하, 각 `consumer`들의 큐관리, 큐에 전달되고 가져가는 메시지의 `정합성`(sync), 전달 결과를 정확하게 관리하기 위한 `내부 프로세스의 복잡도` 때문이다.

이에 반하여 카프카는 메시징 시스템이 지닌 성능의 단점을 극복하기 위해, 메시지 교환 전달의 `신뢰성 관리`를 프로듀서와 컨슈머 쪽으로 위임(기존 펍섭은 메시지 시스템이 처리), 부하가 많이 걸리는 교환기 기능 역시 `컨슈머`가 만들 수 있도록 열어주어 최대한 **메시징 시스템 내에서의 작업량을 줄이고, 절약한 작업량을 메시지 전달 성능 향상에 집중**함으로써 `고성능 메시징 시스템`을 만들어 내었다.


## 4. 카프카의 특징
> 아래의 특성을 통하여 애플리케이션들은 서로 느슨한 결합도를 유지가능합니다. 이는 MSA에 아주 잘 맞는 특성이라 할 수 있다.

1. 프로듀서오 컨슈머의 분리
	- 카프카는 완변학게 분리된 펍/섭 방식을 적용
	- 이는 메시징 전송에서 보내는 역할과 받는 역할이 완벽하게 분리됨
	- 각 서비스 서버들은 다른 시스템의 상태 유무와 관계없이 카프카로 메시지를 보내는 역할만
	- 메시지를 받는 시스템도 서비스 서버들의 상태유무와 관계없이 카프카에 저장된 메시지만 가져옴

2. 멀티 프로듀서, 멀티 컨슈머
	- 카프카는 하나의 `토픽`에 여러 `프로듀서`/`컨슈머`들이 접근 가능한 구조로 되어있음.
	- 또한 하나의 프로듀서가 하나의 토픽으로만 메시지를 보내는 것이 아닌, 다중의 토픽으로 메시지를 보낼 수도, 컨슈머는 가져올 수 있다.
	- 이러한 특성을 통하여 메시지 수신/발신에 있어서는 `중앙 집중형 구조`를 구성 할 수 있었다. 
3. 디스크(zooKeeper)에 메시지 저장
	- **기존 메시징 시스템과 큰 차이점 중 하나**
		- 메모리에 데이터(휘발성, RAM)를 쓰는 것이아니라, 디스크에 메시지를 저장하고 유지한다.
		- 일반적인 메시징 시스템은 `컨슈머`가 소비하면 큐로부터 메시지를 `pop` 시키지만, 카프카는 데이터를 가져가도 일정기간 동안 데이터를 유지한다
			-  디스크를 사용함으로써 In/Out 속도가 메모리에 비해서 느릴 것이라 판단되는데, 어떻게 해결?
		- 트래픽이 급증해도 데이터 손실 없이 처리 가능
		- 멀티 컨슈머/프로듀서가 가능한 이유도 디스크를 쓰기 때문
		- `디스크에 데이터를 쓰기 때문에 느릴까?` 기존의 디스크 사용법과는 다르게 디스크를 나눠서 쓰는 것이 아닌, 특정 영역의 디스크에 순차적으로 쓰기 때문에 읽어가는 디스크의 영역의 범위를 확 줄일 수 있어 **Read/Write**가 사용할만 하다. 
		- 또한 **카프카는 무조건 디스크에 데이터를 쓴다기 보다는, VM메모리의 일부를 페이지 캐싱으로 사용하기 때문에 속도가 빠르다.**
4.  확장성
	- `카프카 클러스터`는 3~수십대까지의 `브로커`의 부하를 견디며 중지없이 메시지 서버를 확장 시킬 수있다.
5. 높은 성능
	- 고속 처리를 위해 내부적으로 `분산 처리`,`배치처리`,`토픽 파티셔닝을 통한 병렬 처리`를 사용해 높은 성능을 뽑아낸다.




# [Kafka] 클러스터 구성 및 CLI 사용법
> 카프카 3대를 클러스터링 구성을 하여 서버를 띄우고 CLI를 이용해 간단히 카프카를 사용해본다.

MSA의 핵심 메시징 시스템이 되어버린 카프카, 프로덕트 환경에서 카프카 한대만 띄워서 운영한다는 것은 너무 위험하다. 여러 클러스터링을 구성하여 `고가용성`을 높혀야 운영환경에서도 안전하고 신뢰성 있는 메시지 시스템 구성이 될 것이다.

## 0. Kafka 구조
- 카프카 토픽에서 모든 메시지는 바이트의 배열로 표현되며, 카프카 프로듀서는 카프카 토픽에 메시지를 저장하는 애플리케이션이다. 
- 이렇게 프로듀서가 보낸 데이터를 저장하고 있는 모든 토픽은 하나 이상의 파티션으로 나뉘어져있다.
- 각 토픽에 대해 여러개로 나뉘어져 있는 파티션은 메시지를 도착한 순서에 맞게 저장한다. (내부적으로 timestamp를 지님). 
- 카프카에서는 프로듀서와 컨슈머가 수행하는 두가지 중요한 동작이 있다.
	1. 프로듀서는 `로그 선행 기입 파일`(가장 최근에 update한 파일) 마지막에 메시지를 추가한다.
	2. 컨슈머는 주어진 토픽 파티션에 속한 로그 파일에서 메시지를 가져온다.
- 물리적으로 각 토픽은 자신에게 할당된 하나 이상의 파티션을 다른 브로커(카프카 데몬 서버 등)들에게 균등하게 분배된다.
- 이상적으로 카프카 파이프라인은 브로커별로 파티션과 각 시스템의 모든 토픽에 대해 균등하게 분배되어야 한다.
- 컨슈머는 토픽에 대한 구독 또는 이런 토픽으로 부터 메시지를 수신하는 애플리케이션이다.


- 전형적인 카프카 클러스터는 `다중브로커`로 구성된다.
	- `다중브로커`
		- 클러스터에 대한 메시지 읽기와 쓰기 작업의 부하 분산을 돕는다.   
		- **각 브로커는 자신의 상태를 저장하지 않지만, Zookeeper를 사용해 상태 정보를 유지한다. **
	- 각각의 토픽 파티션에는 리더로 활동하는 브로커가 하나씩 있고, 0개 이상의 팔로워를 갖는다.
	- 여느 리더/팔로워 관계와 비슷하게 리더는 해당하는 파티션의 읽기/쓰기 요청을 관리한다.
	- 여기서 `zooKeeper`는 카프카 클러스터 안에서 카프카 브로커와 컨슈머를 관리하고 조정한다. 또한 브로커의 추가나 기존 브로커의 장애를 감시한다.
	- 예전 카프카 버전에서는 파티션 오프셋 관리도 Zookeeper에서 관리하였지만, 최근에는 오프셋 관리를 위한 토픽이 생성되어 오프셋 관련 데이터를 하나의 토픽으로 관리한다. 

### 0-1. 메시지 토픽
> 요약: **토픽 -> 파티션(리더 브로커, 팔로워 브로커) -> 메시지 -> tiemstamp**로 정렬

- 각 토픽은 비즈니스 관점에서 하나의 카테고리가 될 수 있다.
- 용어 설명
	- 보관 기간
		- 토픽 안의 메시지 처리 시간과 상관없이, 정해진 기간 동안만 메시지 저장한다.
		- 기본값은 7일 
	- 공간 유지 정책
		- 메시지의 크기가 임계값에 도달하면 메시지를 지우도록 설정가능하다.
		- 카프카 설계시 공간이 충분해야 원치않은 삭제가 발생하지 않는다.
	- 오프셋
		- `토픽 -> 파티션(리더 브로커, 팔로워 브로커) -> 메시지 -> tiemstamp로 정렬`, 컨슈머는 이러한 저장 구조를 오프셋으로 기록한다.
		- 오프셋 메시지를 컨슈머가  수신하면, 해당 오프셋 이전의 메시지는 컨슈머가 수신했던 메시지로 인식한다.
	- 파티션
		- 카프카 메시지 토픽은 1개 이상의 파티션으로 구성되어 분산된다.
		- 파티션의 숫자는 토픽 생성시 설정 가능
		- 순서가 아주 중요한 경우에는 파티션 수를 1개로 지정하는 것도 고려 가능
	- 리더
		- 파티션은 지정된 복제 팩터에 따라 카프카 클러스터 전역에 걸쳐 복제됨
		- 각 파티션은  리더 브로커와 팔로워 브로커를 가진다
		- 파티션에 대한 모든 읽기/쓰기 권한은 리더를 통해서만 진행된다.
### 0-2. 메시지 파티션
> 각 단위 메시지는 오프셋이라 불리는 숫자에 맞게 할당된다.

- 카프카는 유사한 키를 갖고 있는 메시지가 동일한 파티션으로 전송되도록 하며, 메시지 키의 해시 값을 산출하고 해당 파티션에 메시지를 추가한다. 
- **각 단위 메시지에 대한 시간적인 순서는 토픽에 대해서는 보장되지 않지만, 파티션 안에서는 항상 보장된다. **
	- 하나의 토픽아래 3개의 파티션(a,b,c)이 존재하며, 1,2,3,4,5,6 메시지에 대하여 RR 방식으로 메시지들을 할당했다고 하면  a[1,4], b[2,5], c[3,6] 이렇게 분배가 될 것이다.
	- 만약 컨슈머가 a,b,c 파티션에 대하여 데이터를 수신했고 만약 그 순서가 a,b,c라고 한다면 컨슈머는 `1,4,2,5,3,6`으로 데이터를 받게 될 것이다.
		- 즉 파티션 내에서는 시간적인 순서를 보장하지만 (`1,4`), 전체적인 토픽관점에서는 시간순서가 고려되지 않는다.
		- 그러므로 **순서가 중요한 데이터는 동일한 키를 사용해 동일한 파티션에만 데이터를 pub하거나 토픽에 파티션을 하나만 생성해 하나의 파티션에 시간적인 순서로 데이터를 저장되게 해야 한다.**
### 0-3. 많은 수의 파티션을 구성하는 경우의 장단점
- 장점
	- 높은 `throughput`
		- 파티션이 여러개 된다면 병렬처리 가능
			- 여러 파티션에 대해 쓰기 동작이 여러 쓰레드를 통해 동시에 수행 될 것이기 때문
			- 또한 하나이 컨슈머 그룹 내에서 하나의 파티션 당 하나의 컨슈머가 할당되기 때문에 여러 파티션의 메시지를 여러 컨슈머가 동시에 수신하는 병력 처리 또한 가능하다.
			- **동일한 컨슈머 그룹 안의 하나의 파티션에 대해 여러 컨슈머가 읽기 불가능**
- 단점
	- 프로듀스 메모리 증가
		- 만약 파티션 수가 많아 진다면 일시적으로 프로듀서의 버퍼 메모리가 과도해질 수 있음
	- `고가용성`(절대 고장나지 않음) 문제
		- 여러 파티션을 생성하여 클러스터의 고가용성을 지원하지만, 리더인 파티션이 중지되었을 때 해당 리더에 너무 많은 파티션이 존재한다면 리더 선출에 지연이 생겨 고가용성에 영향을 줄 수 있다.
### 0-4. 복제와 복제로그
복제는 카프카 시스템에서 `신뢰성`을 담당한다. 각 토픽 파티션에 대한 메시지 로그의 복제본은 카프카 클러스터 내의 여러 서버에 걸쳐 관리되며 각 토픽마다 복제 factor를 다르게 지정가능

- 일반적으로 팔로워는 리더의 로그 복사본을 보관
	- **리더가 모든 팔로워로부터 ACK를 받기 전까지는 메시지를 커밋하지 않는다는 뜻. (ack =all 설정시)**
### 0-5. 메시지 프로듀서
- 메시지를 생성하면, 이에 대한 쓰기요청을 생성하여 리더 브로커에게 전송한다.
- 파티셔너는 해당 메시지의 해시 값을 계산하여 어느 파티션에 메시지를 pub할지 전달해준다.
- 이때 해시 값은 메시지 키를 가지고 계산하며 토픽으로 메시지를 기록할 때 제공된다. 만약 null 키를 지닌 메시지라면 RR방식으로 분배된다.
- 각 파티션별로 한개의 리더가 존재하며 읽기/쓰기 요청을 담당한다.
- 프로듀서는 메시지의 ACK를 기다리며, 일반적으로 모든 팔로워 파티션에 대해 복제가 완료되면 커밋을 완료한다.
- 커밋이 완료되지 않다면, 읽기는 허용되지 않는다. ( 메시지 손실 방지 )
- 
### 0-6. 메시지 컨슈머
 - 카프카 토픽을 구독하는 역할을 하는 애플리케이션
 - 컨슈머 그룹 -> 컨슈머(1개이상)
	 - **같은 그룹의 컨슈머들은 동시에 같은 토픽의 서로 다른 파티션에서 메시지를 읽어온다.**
	 - **반면 다른 그룹의 컨슈머들은  서로 다른 토픽에서 메시지를 읽어들이기 때문에 독립적으로 메시지 사용이 가능하다. **


## 1. Kafka Cluster
- Kafka Clients
	- Kafka Producers....
	- Kafka Consumers...
	- Kafka Connect
	- Kafka Streams
	- Kafka Admin
- Kafka Cluster
	- Kafka Broker
- Zookeeper Cluster
	- Zookeeper Server
- Admin Config Tools for Zookeeper

여기서 Zookeeper란  간단히 말해 **분산환경 애플리케이션을 중앙에서 관리해주는 디렉토리 구조의 분산 코디네이터**이다.. (what? 분산 코디네이터가 뭐고, Hadoop 같은 분산 DB, Docker, Kubernetics와의 관계는 어떻게 되지?)
	- Lead(1)/Follow(n-1) 관계로 n개의 클러스터들을 보유하며, 장애 복구 시 다수결의 원칙을 따르기 때문에 홀수 개의 클러스터를 생성하는 것이 일반적
	- 주키퍼와 카프카 연동설정
	- `zookeeper.connect=localhost:2181,localhost:2182,localhost:2183/kafka-broker`
		- `kafka-broker`란? 만약 각각 다른 용도의 카프카 클러스터를 2세트 운영한다고 가정하고, 주키퍼는 같은 주키퍼 클러스터를 이용한다고 생각해보자. 이경우 `zookeeper.connect =... kafka-brocker`를 입력하지 않는다면 카프카 클러스터 2세트가 주키퍼의 루트 디렉토리에 동일한 구조의 데이터를 쓰게 되고 그러면 카프카 클러스터 2세트가 데이터 충돌이 나게된다.  그렇기 때문에 `kafka-broker`라고 입력하여 주키퍼의 루트디렉토리가 아닌 `/kafka-broker/`라는 디렉토리를 하나 생성하여 아예 카프카 클러스터 1대의 전용 디렉토리를 구성해 주는 것

## 2. Kafka Producer / JAVA & CLI
> kafka 프로듀서란 메시지를 생산해서 카프카의 토픽으로 메시지를 보내는 역할을 하는 애플리케이션, 서버이다.
- `ISR`그룹 : @TODO: 추가적인 학습 필요
	- kafka에서 도입한 기능
	- 복제본들이 들어있는 클러스터 인스턴스 그룹
	- 리더(zookeeper 리더/follower) 선출이 되기 위해선 ISR에 들어있어야 한다.
		- 현재 리더 클러스터가 빠지면, ISR중에서 카프카 컨트롤러가 리더를 선출함.
- 프로듀서 주요 기능
	- 메시지별 토픽 파티션 매핑
	- 파티션 리더에 요청 보내기
	- 키/값을 정해 키를 가진 모든 메시지를 동일한 파티션으로 전송
	- 파티션은 라운드 로빈(round-robin)방식으로 균등하게 배분
